{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from ortools.sat.python import cp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the finance_utils function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "def get_adj_close_from_stocks(stocks, start_date, end_date):\n",
    "    \"\"\"\n",
    "        Extract Adjusted Close from mentioned stocks on specific dates\n",
    "        Adj Close => Closing price adjusted \n",
    "                    for splits and dividend distributions\n",
    "    \"\"\"\n",
    "    adj_close_df = pd.DataFrame()\n",
    "    \n",
    "    for s in stocks:\n",
    "        data = yf.download(s, start=start_date, end=end_date, auto_adjust=False)\n",
    "        adj_close_df[s] = data['Adj Close']\n",
    "    \n",
    "    return adj_close_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the markovitz utils function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_deviation(weights, cov_matrix):\n",
    "    variance = weights.T @ cov_matrix @ weights\n",
    "    return np.sqrt(variance)\n",
    "\n",
    "def expected_return(weights, log_returns):\n",
    "    return np.sum(log_returns.mean() * weights) * 252\n",
    "\n",
    "def sharpe_ratio(weights, log_returns, cov_matrix, risk_free_rate):\n",
    "\tp_return = expected_return(weights, log_returns) - risk_free_rate\n",
    "\treturn p_return / standard_deviation(weights, cov_matrix)\n",
    "\n",
    "def negative_sharpe_ratio(weights, log_returns, cov_matrix, risk_free_rate):\n",
    "    return -sharpe_ratio(weights, log_returns, cov_matrix, risk_free_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining all test inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = ['AAPL', 'DSY.PA']\n",
    "start_date = datetime(2023, 1, 1)\n",
    "end_date = datetime(2024, 1, 1)\n",
    "bounds =[(0.25, 0.75), (0.25, 0.75)]\n",
    "risk_rate = 0.15\n",
    "SCALE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_portfolio_with_cpsat(stocks, start_date, end_date, bounds, risk_rate):\n",
    "    \"\"\"\n",
    "    Optimize a portfolio using CP-SAT to find the optimal weights\n",
    "    \n",
    "    Parameters:\n",
    "    - stocks: List of stock symbols\n",
    "    - start_date: Start date for historical data\n",
    "    - end_date: End date for historical data\n",
    "    - bounds: List of (min, max) weight bounds for each stock\n",
    "    - risk_rate: Risk tolerance parameter (0-1, higher means more aggressive)\n",
    "    \"\"\"\n",
    "    # Step 1: Get historical data\n",
    "    adj_close_df = get_adj_close_from_stocks(stocks, start_date, end_date)\n",
    "    \n",
    "    # Step 2: Calculate returns and covariance\n",
    "    returns = adj_close_df.pct_change().dropna()\n",
    "    expected_returns = returns.mean()\n",
    "    cov_matrix = returns.cov()\n",
    "    \n",
    "    # Step 3: Set up CP-SAT model to generate valid weight combinations\n",
    "    precision = 1  # 5% increments (0.05)\n",
    "    \n",
    "    # Create the model\n",
    "    model = cp_model.CpModel()\n",
    "    \n",
    "    # Create integer variables for weights (as percentages)\n",
    "    weight_vars = []\n",
    "    for i, (lower_bound, upper_bound) in enumerate(bounds):\n",
    "        # Convert bounds to integers (percentage points)\n",
    "        lower = int(lower_bound * 100)\n",
    "        upper = int(upper_bound * 100)\n",
    "        \n",
    "        # Create integer variable\n",
    "        w = model.new_int_var(lower, upper, f\"weight_{i}\")\n",
    "        weight_vars.append(w)\n",
    "    \n",
    "    # Add constraint: weights sum to 100%\n",
    "    model.add(sum(weight_vars) == 100)\n",
    "    \n",
    "    # Add constraint: weights are multiples of precision\n",
    "    # Fix: Use add_modulo_equality instead of % operator\n",
    "    for w in weight_vars:\n",
    "        model.add_modulo_equality(0, w, precision)\n",
    "    \n",
    "    # We'll use a callback to collect solutions\n",
    "    class SolutionCollector(cp_model.CpSolverSolutionCallback):\n",
    "        def __init__(self, weight_vars):\n",
    "            cp_model.CpSolverSolutionCallback.__init__(self)\n",
    "            self.weight_vars = weight_vars\n",
    "            self.solutions = []\n",
    "            \n",
    "        def on_solution_callback(self):\n",
    "            weights = [self.Value(v) / 100.0 for v in self.weight_vars]\n",
    "            self.solutions.append(weights)\n",
    "    \n",
    "    # Set up the solver\n",
    "    solver = cp_model.CpSolver()\n",
    "    solver.parameters.enumerate_all_solutions = True\n",
    "    \n",
    "    # Create and register the solution collector\n",
    "    solution_collector = SolutionCollector(weight_vars)\n",
    "    \n",
    "    # Solve the model\n",
    "    status = solver.solve(model, solution_collector)\n",
    "    \n",
    "    if not solution_collector.solutions:\n",
    "        return \"No feasible portfolios found\"\n",
    "    \n",
    "    # Step 4: Evaluate each feasible portfolio\n",
    "    possible_portfolios = []\n",
    "    for weights in solution_collector.solutions:\n",
    "        # Calculate expected return and risk\n",
    "        expected_return = sum(weights[i] * expected_returns[i] for i in range(len(stocks)))\n",
    "        risk = np.sqrt(np.dot(weights, np.dot(cov_matrix, weights)))\n",
    "        \n",
    "        # Score based on risk_rate\n",
    "        # Higher risk_rate means we prefer higher returns (more aggressive)\n",
    "        # Lower risk_rate means we prefer lower risk (more conservative)\n",
    "        score = risk_rate * expected_return - (1 - risk_rate) * risk\n",
    "        \n",
    "        possible_portfolios.append({\n",
    "            \"weights\": {stocks[i]: weights[i] for i in range(len(stocks))},\n",
    "            \"expected_return\": expected_return,\n",
    "            \"risk\": risk,\n",
    "            \"score\": score\n",
    "        })\n",
    "    \n",
    "    # Find the portfolio with the highest score\n",
    "    best_portfolio = max(possible_portfolios, key=lambda p: p[\"score\"])\n",
    "    \n",
    "    # Return just the final weights as an array like [0.5, 0.5]\n",
    "    optimized_weights = np.array(list(best_portfolio[\"weights\"].values()))\n",
    "    return optimized_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello here are the results [0.5 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_24187/4129414322.py:16: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  returns = adj_close_df.pct_change().dropna()\n",
      "/tmp/ipykernel_24187/4129414322.py:73: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  expected_return = sum(weights[i] * expected_returns[i] for i in range(len(stocks)))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Run the optimization\n",
    "result = optimize_portfolio_with_cpsat(stocks, start_date, end_date, bounds, risk_rate)\n",
    "print(\"Hello here are the results\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata_kernel",
   "language": "python",
   "name": "bigdata_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
