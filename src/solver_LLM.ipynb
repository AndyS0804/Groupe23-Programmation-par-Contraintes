{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/homebrew/lib/python3.11/site-packages (1.69.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/cerdricdamais/Library/Python/3.11/lib/python/site-packages (from openai) (3.6.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/lib/python3.11/site-packages (from openai) (2.11.0)\n",
      "Requirement already satisfied: sniffio in /Users/cerdricdamais/Library/Python/3.11/lib/python/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/cerdricdamais/Library/Python/3.11/lib/python/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/cerdricdamais/Library/Python/3.11/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in /opt/homebrew/lib/python3.11/site-packages (1.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai\n",
<<<<<<< HEAD
    "import openai"
=======
    "%pip install python-dotenv"
>>>>>>> 6aa4b08 (feat: LLM solver next steps should be to integrate with the SCP)
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "API_KEY = \"sk-proj-1234567890\""
=======
    "import json\n",
    "import random\n",
    "import openai\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n"
>>>>>>> 6aa4b08 (feat: LLM solver next steps should be to integrate with the SCP)
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
=======
    "def is_valid_number_format(value):\n",
    "    pattern = r'^-?\\d+(\\.\\d+)?$'\n",
    "    return bool(re.match(pattern, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "def load_word_list():\n",
    "    with open(\"words_alpha.txt\", \"r\") as file:\n",
    "        for line in file:\n",
    "            word_list.append(line.strip())\n",
    "    return word_list\n",
    "\n",
    "word_list = load_word_list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if OPENAI_API_KEY is None:\n",
    "    raise ValueError(\"The OPENAI_API_KEY environment variable is not set.\")\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import random\n",
    "\n",
>>>>>>> 6aa4b08 (feat: LLM solver next steps should be to integrate with the SCP)
    "class LanguageAgent:\n",
    "    def __init_(self, model_name, strategy_agent):\n",
    "        self.model_name = model_name\n",
    "        self.client = openai.OpenAI(api_key=self.api_key)\n",
    "        self.strategy_agent = strategy_agent\n",
    "    \n",
    "        def suggest_word(self, word_list, constraints):\n",
    "            prompt = f\"\"\"\n",
    "            You are a language model that suggests words for a wordle game.\n",
    "            You are given a list of words and some constraints.\n",
    "            You need to suggest a word that matches the constraints.\n",
    "            \"\"\"\n",
    "\n",
    "            try:\n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=self.model_name,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": prompt},\n",
    "                        {\"role\": \"user\", \"content\": word_list},\n",
    "                        {\"role\": \"user\", \"content\": constraints}\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                if response.choices:\n",
    "                    response_content = response.choices[0].message.content\n",
    "                    score = self.strategy_agent.evaluate_suggestion(response_content, constraints)\n",
    "                    \n",
    "                    if score > 0.8:\n",
    "                        return response_content\n",
    "                    else:\n",
    "                        \n",
    "                        return self.suggest_word(word_list, constraints)\n",
    "                else:\n",
    "                    raise ValueError(\"No choices returned from the API.\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 22,
>>>>>>> 6aa4b08 (feat: LLM solver next steps should be to integrate with the SCP)
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyAgent:\n",
    "    def __init__(self, model_name, api_key):\n",
    "        self.model_name = model_name\n",
    "        self.api_key = api_key\n",
    "        self.client = OpenAI(api_key=self.api_key)\n",
    "\n",
    "    def evaluate_suggestion(self, suggestion, constraints):\n",
    "        prompt = f\"\"\"\n",
    "        You are a language model that evaluates a suggestion for a wordle game.\n",
    "        You are given a suggestion and some constraints.\n",
    "        You need to evaluate the suggestion and return a score between 0 and 1.\n",
    "        \"\"\"\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 23,
>>>>>>> 6aa4b08 (feat: LLM solver next steps should be to integrate with the SCP)
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonitorAgent:\n",
    "    def __init__(self, word_list):\n",
    "        self.api_key = API_KEY\n",
    "        self.client = openai.OpenAI(api_key=self.api_key)\n",
    "        self.constraints = {\n",
    "            'green': {},\n",
    "            'yellow': set(),\n",
    "            'grey': set()\n",
    "        }\n",
    "\n",
    "    def generate_word_to_guess(self, word_list):\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def update_constraints(self, guess, feedback):\n",
    "        for i, (letter, result) in enumerate(zip(guess, feedback)):\n",
    "            if result == 'green':\n",
    "                self.constraints['green'][i] = letter\n",
    "            elif result == 'yellow':\n",
    "                self.constraints['yellow'].add(letter)\n",
    "            elif result == 'grey':\n",
    "                self.constraints['grey'].add(letter)\n",
    "    \n",
    "    def generate_feedback(self, guess, word):\n",
    "        feedback = []\n",
    "        for i, letter in enumerate(guess):\n",
    "            if letter == word[i]:\n",
    "                feedback.append('green')\n",
    "            elif letter in word:\n",
    "                feedback.append('yellow')\n",
    "            else:\n",
    "                feedback.append('grey')\n",
    "        return feedback\n",
    "    \n",
    "    def solve_wordle(self, word_list):\n",
    "        constraints = {\n",
    "            'green': {},\n",
    "            'yellow': set(),\n",
    "            'grey': set()\n",
    "        }\n",
    "\n",
    "        while True:\n",
    "            suggestion = self.language_agent.suggest_word(word_list, constraints)\n",
    "            feedback = self.generate_feedback(suggestion, word)\n",
    "            self.update_constraints(suggestion, feedback)\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
=======
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_agent:StrategyAgent = StrategyAgent(model_name=\"gpt-4o-mini\", api_key=OPENAI_API_KEY)\n",
    "language_agent:LanguageAgent = LanguageAgent(model_name=\"gpt-4o-mini\", strategy_agent=strategy_agent, api_key=OPENAI_API_KEY)\n",
    "agent:MonitorAgent = MonitorAgent(language_agent, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Wordle solver...\n",
      "Word to guess: peppy\n",
      "Word to guess: peppy\n",
      "Score_str is :  broad\n",
      "Score: broad\n",
      "Suggestion: broad\n",
      "Current constraints: {'green': {}, 'yellow': set(), 'grey': {'r', 'b', 'd', 'a', 'o'}}\n",
      "Current guess: broad\n",
      "Feedback: ['grey', 'grey', 'grey', 'grey', 'grey']\n",
      "--------------------------------\n",
      "Score_str is :  timid\n",
      "Score: timid\n",
      "Suggestion: timid\n",
      "Current constraints: {'green': {}, 'yellow': set(), 'grey': {'r', 'm', 't', 'b', 'd', 'a', 'i', 'o'}}\n",
      "Current guess: timid\n",
      "Feedback: ['grey', 'grey', 'grey', 'grey', 'grey']\n",
      "--------------------------------\n",
      "Score_str is :  squat\n",
      "Score: squat\n",
      "Suggestion: squat\n",
      "Current constraints: {'green': {}, 'yellow': set(), 'grey': {'r', 'm', 'u', 't', 's', 'b', 'd', 'q', 'a', 'i', 'o'}}\n",
      "Current guess: squat\n",
      "Feedback: ['grey', 'grey', 'grey', 'grey', 'grey']\n",
      "--------------------------------\n",
      "Score_str is :  whelp\n",
      "Score: whelp\n",
      "Suggestion: whelp\n",
      "Current constraints: {'green': {}, 'yellow': {'e', 'p'}, 'grey': {'r', 'w', 'm', 'u', 't', 's', 'l', 'h', 'b', 'd', 'q', 'a', 'i', 'o'}}\n",
      "Current guess: whelp\n",
      "Feedback: ['grey', 'grey', 'yellow', 'grey', 'yellow']\n",
      "--------------------------------\n",
      "Score_str is :  peppy\n",
      "Score: peppy\n",
      "Suggestion: peppy\n",
      "--------------------------------\n",
      "Feedback:  ['green', 'green', 'green', 'green', 'green']\n",
      "Found the word: peppy\n",
      "Number of guesses: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'peppy'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.solve_wordle(word_list)"
   ]
  },
  {
   "cell_type": "code",
>>>>>>> 6aa4b08 (feat: LLM solver next steps should be to integrate with the SCP)
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
